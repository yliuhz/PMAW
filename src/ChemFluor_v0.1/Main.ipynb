{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please input the job type you want to do.\n",
      "1: predict EM;\n",
      "2: predict ABS;\n",
      "3: classify QY;\n",
      "4: regress QY;\n",
      "0: quit\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import csv\n",
    "from sklearn.externals import joblib\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "\n",
    "#get all *.csv files in given path\n",
    "def get_all_csv_name(path):\n",
    "    filename_list = []\n",
    "    for folderName, subfolders, filenames in os.walk(path):\n",
    "        for file_name in filenames:\n",
    "            if '.csv' in file_name:\n",
    "                filename_list.append(file_name)\n",
    "    return filename_list\n",
    "\n",
    "#read all test file, returning molecular name array y and fingerprint array X\n",
    "def read_test_csv(filename_list):\n",
    "    X_temp = []\n",
    "    for filename in filename_list:\n",
    "        with open('./put_your_predict_file_here/' + filename, 'r') as f:\n",
    "            f_csv = csv.reader(f)\n",
    "            for row in f_csv:\n",
    "                X_temp.append(row)\n",
    "    y = [example[0] for example in X_temp]\n",
    "    X_np_temp = np.array(X_temp)\n",
    "    X = X_np_temp[:, 1:]\n",
    "    X.astype('float64')\n",
    "    return X, y\n",
    "\n",
    "#read all train file, returning label array y and fingerprint array X\n",
    "def read_train_csv_EM(filename_list):\n",
    "    X_temp = []\n",
    "    #read every newly added training dataset\n",
    "    for filename in filename_list:\n",
    "        with open('./put_your_train_file_here/' + filename, 'r') as f:\n",
    "            f_csv = csv.reader(f)\n",
    "            for row in f_csv:\n",
    "                X_temp.append(row)\n",
    "    #read default training dataset\n",
    "    with open('./model/Emission_Database.csv', 'r') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        for row in f_csv:\n",
    "            X_temp.append(row)\n",
    "    for i in range(0, len(X_temp)):\n",
    "        X_temp[i] = [float(j) for j in X_temp[i]]\n",
    "    X_np_temp = np.array(X_temp)\n",
    "    y = X_np_temp[:, 0]\n",
    "    X = X_np_temp[:, 1:]\n",
    "    return X, y\n",
    "\n",
    "#read all train file, returning label array y and fingerprint array X\n",
    "def read_train_csv_ABS(filename_list):\n",
    "    X_temp = []\n",
    "    #read every newly added training dataset\n",
    "    for filename in filename_list:\n",
    "        with open('./put_your_train_file_here/' + filename, 'r') as f:\n",
    "            f_csv = csv.reader(f)\n",
    "            for row in f_csv:\n",
    "                X_temp.append(row)\n",
    "    #read default training dataset\n",
    "    with open('./model/Absorption_Database.csv', 'r') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        for row in f_csv:\n",
    "            X_temp.append(row)\n",
    "    for i in range(0, len(X_temp)):\n",
    "        X_temp[i] = [float(j) for j in X_temp[i]]\n",
    "    X_np_temp = np.array(X_temp)\n",
    "    y = X_np_temp[:, 0]\n",
    "    X = X_np_temp[:, 1:]\n",
    "    return X, y\n",
    "\n",
    "#read all train file, returning label array y and fingerprint array X\n",
    "def read_train_csv_QY(filename_list, thereshold=0.25):\n",
    "    X_temp = []\n",
    "    #read every newly added training dataset\n",
    "    for filename in filename_list:\n",
    "        with open('./put_your_train_file_here/' + filename, 'r') as f:\n",
    "            f_csv = csv.reader(f)\n",
    "            for row in f_csv:\n",
    "                X_temp.append(row)\n",
    "    #read default training dataset\n",
    "    with open('./model/PLQY_Classification_Database.csv', 'r') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        for row in f_csv:\n",
    "            X_temp.append(row)\n",
    "\n",
    "    for i in range(0, len(X_temp)):\n",
    "        X_temp[i] = [float(j) for j in X_temp[i]]\n",
    "    X_np_temp = np.array(X_temp)\n",
    "    y = X_np_temp[:, 0]\n",
    "    X = X_np_temp[:, 1:]\n",
    "    #classify label based on QY value\n",
    "    for u in range(0, np.size(y)):\n",
    "        if y[u] < thereshold:\n",
    "            y[u] = 0\n",
    "        else:\n",
    "            y[u] = 1\n",
    "    return X, y\n",
    "\n",
    "def read_train_csv_QY_reg_no_oversampling(filename_list):\n",
    "    X_temp = []\n",
    "    #read every newly added training dataset\n",
    "    for filename in filename_list:\n",
    "        with open('./put_your_train_file_here/' + filename, 'r') as f:\n",
    "            f_csv = csv.reader(f)\n",
    "            for row in f_csv:\n",
    "                X_temp.append(row)\n",
    "    #read default training dataset\n",
    "    with open('./model/PLQY_Regression_Database_high.csv', 'r') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        for row in f_csv:\n",
    "            X_temp.append(row)\n",
    "    with open('./model/PLQY_Regression_Database_low.csv', 'r') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        for row in f_csv:\n",
    "            X_temp.append(row)\n",
    "\n",
    "    X_np_temp = np.array(X_temp)\n",
    "    y = X_np_temp[:, 0]\n",
    "    X = X_np_temp[:, 1:]\n",
    "    y = y.astype(np.float)\n",
    "    X = X.astype(np.float)\n",
    "    return X, y\n",
    "\n",
    "def read_train_csv_QY_reg_with_oversampling(filename_list):\n",
    "    X_temp = []\n",
    "    #read every newly added training dataset\n",
    "    for filename in filename_list:\n",
    "        with open('./put_your_train_file_here/' + filename, 'r') as f:\n",
    "            f_csv = csv.reader(f)\n",
    "            for row in f_csv:\n",
    "                X_temp.append(row)\n",
    "    #read default training dataset\n",
    "    with open('./model/PLQY_Regression_Database_high.csv', 'r') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        for row in f_csv:\n",
    "            X_temp.append(row)\n",
    "\n",
    "    whole_high = np.array(X_temp)\n",
    "\n",
    "    X_temp = []\n",
    "    with open('./model/PLQY_Regression_Database_low.csv', 'r') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        for row in f_csv:\n",
    "            X_temp.append(row)\n",
    "\n",
    "    whole_low = np.array(X_temp)\n",
    "    whole = np.concatenate((whole_low,whole_high))\n",
    "    whole = np.concatenate((whole,whole_high))\n",
    "    whole = np.concatenate((whole,whole_high))\n",
    "    y = whole[:, 0]\n",
    "    X = whole[:, 1:]\n",
    "    y = y.astype(np.float)\n",
    "    X = X.astype(np.float)\n",
    "    return X, y\n",
    "\n",
    "#print result\n",
    "def output_result(mol_result, mol_name, mol_type):\n",
    "    if mol_type == 'QY Classification':\n",
    "        #QY result is the probability of being one, so thereshold is set to 0.5\n",
    "        mol_result_new=[]\n",
    "        for i in range(0, len(mol_name)):\n",
    "            if mol_result[i] < 0.5:\n",
    "                mol_result_new.append(\"0 PLQY<0.25\") \n",
    "            else:\n",
    "                mol_result_new.append(\"1 PLQY>0.25\") \n",
    "        mol_result = mol_result_new\n",
    "\n",
    "    long_string = str(mol_type) + ' results:\\n'\n",
    "    for i in range(0, len(mol_name)):\n",
    "        long_string = long_string + str(\n",
    "            mol_name[i]) + ' ' + str(mol_type) + ': ' + str(\n",
    "                mol_result[i]) + '\\n'\n",
    "    print(long_string)\n",
    "    with open(\n",
    "            str(mol_type) + 'results' + time.strftime(\"%H%M%S\") + '.txt',\n",
    "            'w') as file_handle:\n",
    "        file_handle.write(long_string)\n",
    "        file_handle.close()\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "while True:\n",
    "\n",
    "    #search for every *.csv file in train folder and predict folder\n",
    "    train_files = get_all_csv_name('./put_your_train_file_here/')\n",
    "    test_files = get_all_csv_name('./put_your_predict_file_here/')\n",
    "    pre_type = input(\n",
    "        'please input the job type you want to do.\\n1: predict EM;\\n2: predict ABS;\\n3: classify QY;\\n4: regress QY;\\n0: quit\\n '\n",
    "    )\n",
    "    #if enter 0 then quit\n",
    "    pre_type = int(pre_type)\n",
    "    if pre_type == 0:\n",
    "        break\n",
    "\n",
    "    train_type = input('New models? 0: No; 1:Yes\\n ')\n",
    "    train_type = int(train_type)\n",
    "\n",
    "    if train_type == 0:\n",
    "        #load model\n",
    "        if pre_type == 1:\n",
    "            clf = joblib.load('./model/Emsision_Model_for_Predict.m')\n",
    "        elif pre_type == 2:\n",
    "            clf = joblib.load('./model/Absorption_Model_for_Predict.m')\n",
    "        elif pre_type == 3:\n",
    "            clf = joblib.load('./model/PLQY_Model_for_Classification.m')\n",
    "        elif pre_type == 4:\n",
    "            oversampling_type = input('Use oversampled model? 0: No; 1:Yes\\n ')\n",
    "            oversampling_type = int(oversampling_type)\n",
    "            if oversampling_type == 0:\n",
    "                clf = joblib.load('./model/PLQY_Model_for_Regression_no_Oversample.pkl')\n",
    "            else:\n",
    "                clf = joblib.load('./model/PLQY_Model_for_Regression_with_Oversample.pkl')\n",
    "\n",
    "        #read fingerprint and predict result\n",
    "        X_pre, X_name = read_test_csv(test_files)\n",
    "        y_pre = clf.predict(X_pre)\n",
    "        #show result\n",
    "        if pre_type == 1:\n",
    "            output_result(y_pre, X_name, 'EM')\n",
    "        elif pre_type == 2:\n",
    "            output_result(y_pre, X_name, 'ABS')\n",
    "        elif pre_type == 3:\n",
    "            output_result(y_pre, X_name, 'QY Classification')\n",
    "        elif pre_type == 4:\n",
    "            output_result(y_pre, X_name, 'QY Regression')\n",
    "\n",
    "    elif train_type == 1:\n",
    "        #train model with new database and predict\n",
    "        if pre_type == 1:\n",
    "            clf = GradientBoostingRegressor(learning_rate=0.05,\n",
    "                                            max_depth=31,\n",
    "                                            max_features=300,\n",
    "                                            min_samples_leaf=20,\n",
    "                                            n_estimators=1000)\n",
    "            #read fingerprint and train model\n",
    "            X_train, y_train = read_train_csv_EM(train_files)\n",
    "            print('training')\n",
    "            clf.fit(X_train, y_train)\n",
    "            X_pre, X_name = read_test_csv(test_files)\n",
    "            #predict and show result\n",
    "            y_pre = clf.predict(X_pre)\n",
    "            output_result(y_pre, X_name, 'EM')\n",
    "        elif pre_type == 2:\n",
    "            clf = GradientBoostingRegressor(learning_rate=0.05,\n",
    "                                            max_depth=31,\n",
    "                                            max_features=300,\n",
    "                                            min_samples_leaf=20,\n",
    "                                            n_estimators=1000)\n",
    "            #read fingerprint and train model\n",
    "            X_train, y_train = read_train_csv_ABS(train_files)\n",
    "            print('training')\n",
    "            clf.fit(X_train, y_train)\n",
    "            X_pre, X_name = read_test_csv(test_files)\n",
    "            #predict and show result\n",
    "            y_pre = clf.predict(X_pre)\n",
    "            output_result(y_pre, X_name, 'ABS')\n",
    "        elif pre_type == 3:\n",
    "            clf = lgb.LGBMRegressor(n_estimators=600,\n",
    "                                    learning_rate=0.1,\n",
    "                                    max_depth=70,\n",
    "                                    num_leaves=45,\n",
    "                                    objective='binary')\n",
    "            #read fingerprint and train model, and setting thereshold\n",
    "            X_train, y_train = read_train_csv_QY(train_files, thereshold = 0.25)\n",
    "            print('training')\n",
    "            clf.fit(X_train, y_train)\n",
    "            X_pre, X_name = read_test_csv(test_files)\n",
    "            #predict and show result\n",
    "            y_pre = clf.predict(X_pre)\n",
    "            output_result(y_pre, X_name, 'QY Classification')\n",
    "        elif pre_type == 4:\n",
    "            clf = lgb.LGBMRegressor(learning_rate=0.1, \n",
    "                                    max_depth=20, \n",
    "                                    num_leaves=20,\n",
    "                                    n_estimators=1000)\n",
    "            oversampling_type = input('Oversampling? 0: No; 1:Yes\\n ')\n",
    "            oversampling_type = int(oversampling_type)\n",
    "            if oversampling_type == 0:\n",
    "                X_train, y_train = read_train_csv_QY_reg_no_oversampling(train_files)\n",
    "            else:\n",
    "                X_train, y_train = read_train_csv_QY_reg_with_oversampling(train_files)\n",
    "            print('training')\n",
    "            clf.fit(X_train, y_train)\n",
    "            X_pre, X_name = read_test_csv(test_files)\n",
    "            #predict and show result\n",
    "            y_pre = clf.predict(X_pre)\n",
    "            output_result(y_pre, X_name, 'QY Regression')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
