{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['01-15-descriptor-merged.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15-descriptor-merged.csv (960, 393) (960, 393)\n",
      "Shape:  (960, 393)\n"
     ]
    }
   ],
   "source": [
    "Merged = pd.DataFrame()\n",
    "\n",
    "origin_total = 0\n",
    "\n",
    "for filen in files:\n",
    "    try:\n",
    "        data = pd.read_csv(filen, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        print(filen, ': ', e.__class__.__name__, e)\n",
    "    else:\n",
    "        origin_shape = data.shape\n",
    "\n",
    "        origin_total += origin_shape[0]\n",
    "\n",
    "        col_names = data.columns\n",
    "\n",
    "        print(filen, origin_shape, data.shape)\n",
    "        \n",
    "        Merged = pd.concat([Merged, data], axis=1)\n",
    "        print('Shape: ', Merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 393)\n"
     ]
    }
   ],
   "source": [
    "print(Merged.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Merged.iloc[:, :-1]\n",
    "y = Merged.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20/960, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(940, 392) (20, 392) (940,) (20,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([734, 413, 276, 690, 356, 681, 623,  94, 766, 811,  81,  32, 614,\n",
      "            815, 581, 137, 494, 578, 699, 254],\n",
      "           dtype='int64') Int64Index([734, 413, 276, 690, 356, 681, 623,  94, 766, 811,  81,  32, 614,\n",
      "            815, 581, 137, 494, 578, 699, 254],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(X_test.index, y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train,y_train], axis=1)\n",
    "test_data = pd.concat([X_test,y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(940, 393) (20, 393)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('01-15-descriptor-train.csv', index=False, encoding='gb18030')\n",
    "test_data.to_csv('01-15-descriptor-test.csv', index=False, encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15\n",
      "[802, 803, 804, 805, 806, 807, 495, 496, 497, 562, 561, 628, 629, 729, 730]\n"
     ]
    }
   ],
   "source": [
    "aa = list(set(Merged.index) - set(Merged.dropna().index))\n",
    "print(len(aa), Merged.shape[0] - Merged.dropna().shape[0])\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(861, 393)\n"
     ]
    }
   ],
   "source": [
    "Merged = Merged.dropna()\n",
    "print(Merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged.to_csv(files[0], encoding='gb18030', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "files = ['01-15-descriptor-test.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15-descriptor-test.csv (100, 393) (100, 393)\n",
      "Shape:  (100, 393)\n"
     ]
    }
   ],
   "source": [
    "Merged = pd.DataFrame()\n",
    "\n",
    "origin_total = 0\n",
    "\n",
    "for filen in files:\n",
    "    try:\n",
    "        data = pd.read_csv(filen, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        print(filen, ': ', e.__class__.__name__, e)\n",
    "    else:\n",
    "        origin_shape = data.shape\n",
    "\n",
    "        origin_total += origin_shape[0]\n",
    "\n",
    "        col_names = data.columns\n",
    "\n",
    "        print(filen, origin_shape, data.shape)\n",
    "        \n",
    "        Merged = pd.concat([Merged, data], axis=1)\n",
    "        print('Shape: ', Merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 393) (99, 393)\n"
     ]
    }
   ],
   "source": [
    "print(Merged.shape, Merged.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "[28]\n"
     ]
    }
   ],
   "source": [
    "aa = list(set(Merged.index) - set(Merged.dropna().index))\n",
    "print(len(aa), Merged.shape[0] - Merged.dropna().shape[0])\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 393)\n"
     ]
    }
   ],
   "source": [
    "Merged = Merged.dropna()\n",
    "print(Merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged.to_csv(files[0], encoding='gb18030', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged_1 = pd.concat([Merged, test_Merged], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(977, 393)\n"
     ]
    }
   ],
   "source": [
    "print(Merged_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Merged_1.iloc[:, :-1]\n",
    "y = Merged_1.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(977, 196)\n"
     ]
    }
   ],
   "source": [
    "X = X.dropna(axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(977, 197)\n"
     ]
    }
   ],
   "source": [
    "Merged_1 = pd.concat([X,y], axis=1)\n",
    "print(Merged_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877, 393) (100, 393)\n"
     ]
    }
   ],
   "source": [
    "shape1 = Merged.shape\n",
    "shape2 = test_Merged.shape\n",
    "print(shape1, shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged_1.index = [x for x in range(Merged_1.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877, 197)\n"
     ]
    }
   ],
   "source": [
    "Merged = Merged_1.iloc[:shape1[0], :]\n",
    "print(Merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 197)\n"
     ]
    }
   ],
   "source": [
    "Merged = Merged_1.iloc[-shape2[0]:, :]\n",
    "print(Merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged:  (100, 197)\n",
      "Datadl Succeed\n"
     ]
    }
   ],
   "source": [
    "Merged.index = [x for x in range(Merged.shape[0])]\n",
    "Merged_origin = Merged\n",
    "Merged_origin.to_csv('Merged_Origin.csv', index=0, encoding='gb18030')\n",
    "\n",
    "col_names = Merged.columns\n",
    "colNum = np.array([x for x in range(len(col_names))])\n",
    "indexNum = np.array([x for x in range(Merged.shape[0])])\n",
    "sigM = Merged.applymap(np.isreal)\n",
    "sigMall = sigM.all(1)\n",
    "index = indexNum[~sigMall]\n",
    "\n",
    "delList = []\n",
    "\n",
    "for i in index:\n",
    "    col = colNum[~sigM.iloc[i]]\n",
    "    for j in col:\n",
    "        s = Merged[col_names[j]].iloc[i]\n",
    "        try:\n",
    "            s = float(s)\n",
    "        except Exception as e:\n",
    "            print(s, ': ', e.__class__.__name__, e)\n",
    "            print('[', i, ', ', col_names[j], ']')\n",
    "            delList.append(i)\n",
    "            break\n",
    "        else:\n",
    "            Merged[col_names[j]].iloc[i] = s\n",
    "\n",
    "for i in delList:\n",
    "    Merged = Merged.drop(i, axis=0)\n",
    "\n",
    "print('Merged: ', Merged.shape)\n",
    "\n",
    "Merged.to_csv(test_files[0], index=0, encoding='gb18030')\n",
    "\n",
    "try:\n",
    "    Merged = pd.read_csv(test_files[0], encoding='gb18030').astype('float')\n",
    "except Exception as e:\n",
    "    print('Merged: ', e.__class__.__name__, e)\n",
    "else:\n",
    "    print('Datadl Succeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加入onehot标签类别**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC20925SM1_out.csv (1931, 229) (1931, 227)\n",
      "Shape:  (1931, 227)\n",
      "AC20925SM2_out.csv (1931, 229) (1931, 227)\n",
      "Shape:  (1931, 454)\n",
      "AC20925ligand_out.csv (1931, 229) (1931, 227)\n",
      "Shape:  (1931, 681)\n",
      "AC20925metal_out.csv (1931, 229) (1931, 227)\n",
      "Shape:  (1931, 908)\n",
      "AC20925solvent1_out.csv (1931, 229) (1931, 227)\n",
      "Shape:  (1931, 1135)\n",
      "AC20925temperature_out.csv (1931, 2) (1931, 2)\n",
      "Shape:  (1931, 1137)\n",
      "Shape:  (1931, 1146)\n"
     ]
    }
   ],
   "source": [
    "Merged = pd.DataFrame()\n",
    "\n",
    "origin_total = 0\n",
    "\n",
    "for filen in files:\n",
    "    try:\n",
    "        data = pd.read_csv(filen, encoding='gb18030')\n",
    "    except Exception as e:\n",
    "        print(filen, ': ', e.__class__.__name__, e)\n",
    "    else:\n",
    "        origin_shape = data.shape\n",
    "\n",
    "        origin_total += origin_shape[0]\n",
    "\n",
    "        col_names = data.columns\n",
    "        \n",
    "        if 'temperature' not in filen:\n",
    "            data = data.drop(col_names[0], axis=1)\n",
    "            data = data.drop(col_names[-1], axis=1)\n",
    "\n",
    "        print(filen, origin_shape, data.shape)\n",
    "        Merged = pd.concat([Merged, data], axis=1)\n",
    "        print('Shape: ', Merged.shape)\n",
    "        \n",
    "colnames = Merged.columns\n",
    "ee_col = Merged[colnames[-1]]\n",
    "Merged = Merged.drop(colnames[-1], axis=1)\n",
    "Merged = pd.concat([Merged, labels_hot_pd], axis=1)\n",
    "Merged = pd.concat([Merged, ee_col], axis=1)\n",
    "print('Shape: ', Merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接删除无效值:  (0, 1146)\n",
      "Shape:  (1931, 1021)\n"
     ]
    }
   ],
   "source": [
    "col_names = Merged.columns\n",
    "print('直接删除无效值: ', Merged.dropna().shape)\n",
    "\n",
    "X = Merged.iloc[:,:-1]\n",
    "y = Merged.iloc[:,-1]\n",
    "X = X.dropna(axis=1)\n",
    "# X = X.select_dtypes(['number'])\n",
    "Merged = pd.concat([X,y], axis=1)\n",
    "print('Shape: ', Merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensor23\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 99 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 239 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 241 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 243 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 245 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 246 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 247 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 248 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 249 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 431 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 435 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 437 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 438 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 439 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 440 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 441 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 442 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 443 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 444 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 447 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 448 ,  ee ]\n",
      "＞99 :  ValueError could not convert string to float: '＞99'\n",
      "[ 453 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 577 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 579 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 644 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 692 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 828 ,  ee ]\n",
      ">99 :  ValueError could not convert string to float: '>99'\n",
      "[ 832 ,  ee ]\n",
      "<5 :  ValueError could not convert string to float: '<5'\n",
      "[ 1032 ,  ee ]\n",
      "<2 :  ValueError could not convert string to float: '<2'\n",
      "[ 1200 ,  ee ]\n",
      "<2 :  ValueError could not convert string to float: '<2'\n",
      "[ 1201 ,  ee ]\n",
      "<2 :  ValueError could not convert string to float: '<2'\n",
      "[ 1202 ,  ee ]\n",
      "<2 :  ValueError could not convert string to float: '<2'\n",
      "[ 1209 ,  ee ]\n",
      "Merged:  (1898, 1021)\n",
      "Datadl Succeed\n"
     ]
    }
   ],
   "source": [
    "Merged.index = [x for x in range(Merged.shape[0])]\n",
    "Merged_origin = Merged\n",
    "Merged_origin.to_csv('Merged_Origin.csv', index=0, encoding='gb18030')\n",
    "\n",
    "col_names = Merged.columns\n",
    "colNum = np.array([x for x in range(len(col_names))])\n",
    "indexNum = np.array([x for x in range(Merged.shape[0])])\n",
    "sigM = Merged.applymap(np.isreal)\n",
    "sigMall = sigM.all(1)\n",
    "index = indexNum[~sigMall]\n",
    "\n",
    "delList = []\n",
    "\n",
    "for i in index:\n",
    "    col = colNum[~sigM.iloc[i]]\n",
    "    for j in col:\n",
    "        s = Merged[col_names[j]].iloc[i]\n",
    "        try:\n",
    "            s = float(s)\n",
    "        except Exception as e:\n",
    "            print(s, ': ', e.__class__.__name__, e)\n",
    "            print('[', i, ', ', col_names[j], ']')\n",
    "            delList.append(i)\n",
    "            break\n",
    "        else:\n",
    "            Merged[col_names[j]].iloc[i] = s\n",
    "\n",
    "for i in delList:\n",
    "    Merged = Merged.drop(i, axis=0)\n",
    "\n",
    "print('Merged: ', Merged.shape)\n",
    "\n",
    "Merged.to_csv('Merged.csv', index=0, encoding='gb18030')\n",
    "\n",
    "try:\n",
    "    Merged = pd.read_csv('Merged.csv', encoding='gb18030').astype('float')\n",
    "except Exception as e:\n",
    "    print('Merged: ', e.__class__.__name__, e)\n",
    "else:\n",
    "    print('Datadl Succeed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
